{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE`/`raise NotImplementedError` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "671ec45b1c3f056d05b5733e064666de",
     "grade": false,
     "grade_id": "cell-d53558d0f0d03eff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q1** Regarding connections to SQLite, follow the discussion in the reading to explain why, if the path was given as a relative path, we would see three slashes in a row. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a48fdfe91b891b7f8030d7f7d7575b80",
     "grade": true,
     "grade_id": "cell-921c41ad2586c52b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "002bf90b29cabbf887770f069505ab65",
     "grade": false,
     "grade_id": "cell-937f678e4b6182d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q2** Give the code necessary to fetch all data from the `countries` table from the `MySQL` provider, and then to print the land area of Zimbabwe (ZME, the last record in `countries`). Please use your personal username and password that connects you to the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7eb842b50e2cccd1fc22d42dd56ce73e",
     "grade": true,
     "grade_id": "cell-efd92f26dc6014c0",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c02a92ddbabae9f6dae83f9d4c543a1",
     "grade": false,
     "grade_id": "cell-6223469258efaaa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q3** Show how to do the problem above using `read_sql_table()` in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "053b29d12a37e52b160f3c05673fde9f",
     "grade": true,
     "grade_id": "cell-3922a280fad0d360",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd57db45bf57374d5978997c1b83cb31",
     "grade": false,
     "grade_id": "cell-75379bb4fdf872fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q4** Show how to do the problem above using `read_sql_table()` in `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c21513139f6fa7b9c66df1d35d35c571",
     "grade": true,
     "grade_id": "cell-684f1bdde7d9b534",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3e96879ea7ed98683a9b006140a8deb",
     "grade": false,
     "grade_id": "cell-d7abb412dfe19b6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q5** Give a real-world application where you would use `fetchmany()`, and please be clear about the real-world meaning of `chunk_size` in your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1fa1cdfb42b8b94418fc98bcf3d0d1d",
     "grade": true,
     "grade_id": "cell-c4966f75fe567c20",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02f3507bd3de9610d3cc599401b1a360",
     "grade": false,
     "grade_id": "cell-9148bcb45f503f2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q6** The key line of code in the `indicators_life` function is `query = template.format(year, threshold)`, which fills in the `{}` spots with the given parameters. Show how to modify the function so that it selects records of countries with population greater than `x` and gdp per capita greater than `y`. Name your new function `pop_gdp`. It should again have three parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42664964ce11e5e1f6efaade4d452edf",
     "grade": true,
     "grade_id": "cell-5a890b4a8bed09bd",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b66ce3fd9b7be76f9298cd7d415f1dcc",
     "grade": false,
     "grade_id": "cell-e9b758d1c29497e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q7** After `bindparams()` is invoked on a \"prepare\" statement to get to `bound_stmt`, does the `bound_stmt` still have colons in it? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c7d9998425ea95b152c0a1dcb1c6776",
     "grade": true,
     "grade_id": "cell-0abbaf08e4031e2c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "714e460822f3e4d852de7cf11bb68351",
     "grade": false,
     "grade_id": "cell-47def377661ec8d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Q8** Consider the function call `result_proxy = connection.execute(prepare_stmt, yr=1999, threshold=70)`. How many parameters can the `execute` function take? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e73a59f63d390bcb77379c6692e33a12",
     "grade": true,
     "grade_id": "cell-66ab769ed254d2e5",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
