{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import lxml.html as lh\n",
    "import io\n",
    "import os.path\n",
    "\n",
    "dataout = \"_generated\"\n",
    "datadir = \"../../data/22\"\n",
    "\n",
    "protocol = \"http\"\n",
    "location = \"personal.denison.edu\"\n",
    "resourcepath = \"/~bressoud/datasystems/{}\"\n",
    "\n",
    "buildURL = lambda s: \"{}://{}{}\".format(protocol, location, resourcepath.format(s))\n",
    "\n",
    "parser = etree.HTMLParser(remove_blank_text=True)\n",
    "\n",
    "def print_tree(node, pretty_print=True, encoding='utf-8', limit=0):\n",
    "    result = etree.tostring(node, pretty_print=pretty_print)\n",
    "    if isinstance(result, bytes):\n",
    "        result = result.decode(encoding)\n",
    "    if limit > 0:\n",
    "        print(result[:limit])\n",
    "    else:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_string(node):\n",
    "    s = ''\n",
    "    for k, v in node.attrib.items():\n",
    "        nextval = \" {}='{}'\".format(k, v)\n",
    "        s += nextval\n",
    "    return s\n",
    "\n",
    "def print_leaf_node(node, level):\n",
    "    indent = level*'  '\n",
    "    tag_string = \"<{}{}>\".format(node.tag, attr_string(node))\n",
    "    nodetext = str(node.text).strip()\n",
    "    if node.text != None and nodetext != '':\n",
    "        tag_string += nodetext + ''\n",
    "    end_tag = \"</{}>\".format(node.tag)\n",
    "    print(indent, tag_string, end_tag, sep='')\n",
    "    \n",
    "def print_start_tag(node, level):\n",
    "    indent = level*'  '\n",
    "    tag_string = \"<{}{}>\".format(node.tag, attr_string(node))\n",
    "    nodetext = str(node.text).strip()\n",
    "    if node.text != None and nodetext != '':\n",
    "        tag_string += nodetext + ''\n",
    "    print(indent, tag_string, sep='')\n",
    "\n",
    "def print_end_tag(node, level):\n",
    "    indent = level*'  '\n",
    "    tag_string = \"</{}>\".format(node.tag)\n",
    "    print(indent, tag_string, sep='')\n",
    "\n",
    "\n",
    "def print_levels(node, level, maxlevel, maxchildren=30):\n",
    "    if len(node) == 0:\n",
    "        print_leaf_node(node, level)\n",
    "    else:\n",
    "        print_start_tag(node, level)\n",
    "        if len(node) > 0 and level < maxlevel:\n",
    "            for i, child in enumerate(node):\n",
    "                if i < maxchildren:\n",
    "                    print_levels(child, level+1, maxlevel, maxchildren)\n",
    "                else:\n",
    "                    print((level+1)*'  ', '...')\n",
    "                    break\n",
    "        print_end_tag(node, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(datadir, \"ind2016table.html\")\n",
    "os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as f:\n",
    "    tree = etree.parse(f, parser)\n",
    "    root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_levels(root[0][0], 0, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Simple Table\n",
    "\n",
    "> HTML table construct: https://www.w3schools.com/html/html_tables.asp\n",
    "\n",
    "Example URL: http://personal.denison.edu/~bressoud/datasystems/ind2016.html\n",
    "\n",
    "- table\n",
    "    - thead\n",
    "        - tr\n",
    "            - th\n",
    "            - th\n",
    "            - etc.\n",
    "    - tbody\n",
    "        - tr\n",
    "            - td\n",
    "            - td\n",
    "            - etc.\n",
    "        - tr\n",
    "            - td\n",
    "            - td\n",
    "            - etc.\n",
    "        - etc.\n",
    "        \n",
    "Notes:\n",
    "\n",
    "- In our first example, the names of columns and the values for table elements are part in the `text` of the `td` Element.\n",
    "\n",
    "- For some earlier version tables, `thead`/`tbody` are not used and may not be present.  If the web scraper knows they are present, then you don't have to rely on processing a first row one way (to get column headers) and the remaining rows in a different way.  If the table uses `th`, then that helps.  \n",
    "\n",
    "    - Another point of confusion that I have seen is where the HTML parser for a \"Developer Tools\" actually adds in the structure of `thead` and `tbody` when they do not, in fact, exist in the source HTML.  So students see one thing in the developer tools, and then their code is written to use `thead`/`tbody` and they get no matching XPath results.\n",
    "    \n",
    "- For some more complex examples, might have multiple rows of headers before the table data rows begin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = buildURL(\"ind2016.html\")\n",
    "response = requests.get(url)\n",
    "assert response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = etree.parse(io.BytesIO(response.content), parser)\n",
    "root1 = tree1.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = root1.xpath(\".//table/thead/tr/th/text()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = root1.xpath(\".//table//tr/th/text()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdlist = root1.xpath(\".//table//tr/td/text()\")\n",
    "LoL = []\n",
    "fieldcount = 0\n",
    "for item in tdlist:\n",
    "    if fieldcount == 0:\n",
    "        row = []\n",
    "    row.append(item)\n",
    "    if fieldcount < 5:\n",
    "        fieldcount += 1\n",
    "    else:\n",
    "        LoL.append(row)\n",
    "        fieldcount = 0\n",
    "LoL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoL = {}\n",
    "for index, column in enumerate(column_names):\n",
    "    xpath = \".//table//tr/td[{}]/text()\".format(index+1)\n",
    "    DoL[column] = root1.xpath(xpath)\n",
    "DoL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(DoL)\n",
    "df.set_index('code', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Variation: Multiple Tables in a Single Page\n",
    "\n",
    "If the desired table for web scraping is **not** the first table in the page, the above code breaks.  General case might have multiple preceeding tables and even multiple following tables.\n",
    "\n",
    "General solution would be to first use a position or an attribute to get the Element of the **correct** table, and then to do table processing relative to that node, instead of from the root of the document tree.\n",
    "\n",
    "### Possible Variation: More Compicated Data Extraction from `td`\n",
    "\n",
    "A `td` cell in an HTML table may well contain the desired data for a tabular data frame extraction, but could well be \"buried\", and not just be the `text` of the `td` node.  There may be a subtree at the `td` node, and the data might be in a link (`a` reference).  Or it could be part of an attribute, either of the `td` or a subelement.  Or the extracted data may contain \"extra\", like a footnote or icon picture, in addition to the element itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Wikipedia Table\n",
    "\n",
    "Non-API URL: https://en.m.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States_by_population\n",
    "\n",
    "### Goal\n",
    "\n",
    "We see in the rendered page a table of state populations.  Population data and ranks are relative to the 2010 census and population estimates for 2019.  In our case, we are interested in the most recent data, even if it is an estimate, and so we want to extract the current rank (as an integer), the string of the name of the state (we don't care about the state flag picture), and the estimate of the population as of July 1, 2019.  These are the first, third, and fourth columns in the table.\n",
    "\n",
    "### Access\n",
    "\n",
    "To discourage web scraping (in violation of its accepable use and robots.txt policies), pages like the above in fact have HTML that use scripts to generate the content.  So if you fetch the above, you will not find the underlying table.\n",
    "\n",
    "They do provide an API where you can, through the API, request the HTML page content for many pages.  Documentation is: https://en.wikipedia.org/api/rest_v1/. See subsection on page content at https://en.wikipedia.org/api/rest_v1/#/Page%20content.  We are using the fourth version of the API, an HTTP GET going to the `/page/html/{title}` where, for this example, `{title}` is `List_of_states_and_territories_of_the_United_States_by_population`.  Note that, in accordance with the API, this endpoint is accessed in a resource path that starts `/api/rest_v1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Before processing, we retrieve the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://en.wikipedia.org/api/rest_v1/page/html/List_of_states_and_territories_of_the_United_States_by_population\n",
    "\"\"\"\n",
    "\n",
    "protocol = \"https\"\n",
    "location = \"en.wikipedia.org\"\n",
    "resourcepath = \"/api/rest_v1/page/html/{}\"\n",
    "pop_page = \"List_of_states_and_territories_of_the_United_States_by_population\"\n",
    "\n",
    "url = buildURL(pop_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "assert response.status_code == 200\n",
    "\n",
    "tree2 = etree.parse(io.BytesIO(response.content), parser)\n",
    "root2 = tree2.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. See the set of tables in the whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root2.xpath(\"//table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Often a `class` attribute can distinguish tables, so we obtain the class attributes for the set of tables in the document.  If a table does not have a class attribute, it will not appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root2.xpath(\"\"\"//table/@class\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Discover (by inspection in Developer tools) that class of our state population table is `'wikitable sortable'`, so get node list of tables that satisfy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = root2.xpath(\"\"\"//table[@class='wikitable sortable']\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(table_list[0], limit=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We find that the index 0 node in the table_list is the one we want, so we assign to a new variable and print the top three levels of the tree to see its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_table = table_list[0]\n",
    "print(\"table\")\n",
    "limit = 3\n",
    "for child1 in population_table:\n",
    "    print(\" \", child1.tag)\n",
    "    for i, child2 in enumerate(child1):\n",
    "        print(\"   \", child2.tag)\n",
    "        for j, child3 in enumerate(child2):\n",
    "            print(\"     \", child3.tag)\n",
    "            if j > limit:\n",
    "                print(\"      ...\")\n",
    "                break\n",
    "        if i > limit:\n",
    "            print(\"   ...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Conclusion: a `tbody` *is* present, but is not being used for just the body of the table.  The header is part of the body.  We know this because of the `th` nodes.  We also observe that there are **two** rows of header information.  If we look at the rendered result, this makes sense, as we can distinguish the two header rows, along with both some horizontal and vertical spanning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5. Look more closely at the first data-carrying row.\n",
    "    - Be careful in the `xpath`; if we use `//tr[3]` we would get the third row from all five of the tables present in the document.  So we make the xpath relative to the population table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablerow_list = population_table.xpath(\".//tr[3]\")\n",
    "tablerow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datarow = tablerow_list[0]\n",
    "print_tree(datarow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Conclusion: \n",
    "> 1. current state rank is in first `td` in row, and is the text of a `span` node under the `td` Element (note that some tables can use additional `td` elements in the set of rows, used for spacing, borders, and other rendering results.\n",
    "> 2. state rank in 2010 is in second `td` in row; we disregard based on our goals\n",
    "> 3. third `td` contains the state information, and we will explore that further below\n",
    "> 4. fourth `td` contains the estimated population in 2019, and value is in the text of the `td` element.\n",
    "> 5. there are `id` attributes for set of `td` nodes, but (by inspection not shown here) they are **not** consistent between rows.\n",
    ">\n",
    "> So we will use positioning to get the columns (as relative `td` within the row) that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoL = {'rank': None, 'state': None, 'population': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following xpath expression gets the set of rows starting with the first data row, and ending with the last state and before territories and aggregates in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowset = population_table.xpath(\".//tr[position() > 2 and position() < 54]\")\n",
    "firstrow = rowset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_column = [int(row[0].find('span').text) for row in rowset]\n",
    "rank_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_column = population_table.xpath(\n",
    "    \".//tr[position() > 2 and position() < 54]/td[1]/span/text()\")\n",
    "rank_column = [int(s) for s in rank_column]\n",
    "rank_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_pop = lambda p: int(p.replace(\",\", \"\"))\n",
    "pop_column = [convert_pop(row[3].text) for row in rowset]\n",
    "pop_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_column = population_table.xpath(\n",
    "    \".//tr[position() > 2 and position() < 54]/td[4]/text()\")\n",
    "pop_column = [convert_pop(p) for p in pop_column]\n",
    "pop_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_td = firstrow[2]\n",
    "print_tree(state_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure:\n",
    "\n",
    "- `span`\n",
    "    - `figure-inline`\n",
    "        - `span`\n",
    "            - `img`\n",
    "    - `span`\n",
    "- `a`\n",
    "\n",
    "So under the `td`, we have children of a `span` and an `a` (which is a hyperlink reference).  That first span has embedded stuff for the structure of an image and the image itself.  The hyperlink has the information we seek, with the `text` of the `a` having the name of the state.  We want to avoid the attributes of the `a`, as the `href` and `title` attributes have the possiblitiy of being named differently from the state itself.\n",
    "\n",
    "On debugging, found that, for the row containing the District of Columbia, that the `a` is not an immediate child, but instead is under another `span`.  Now, `lxml` supports a `find` that can take a subset of XPath, so the solution that works on the `rowset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_column = [row[2].find('.//a').text for row in rowset]\n",
    "state_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_column = population_table.xpath(\n",
    "    \".//tr[position() > 2 and position() < 54]/td[3]//a/text()\")\n",
    "state_column[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DoL['rank'] = rank_column\n",
    "DoL['state'] = state_column\n",
    "DoL['population'] = pop_column\n",
    "\n",
    "df = pd.DataFrame(DoL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Data Organized as (Nested) Ordered or Unordered Lists\n",
    "\n",
    "> HTML List Constructs: https://www.w3schools.com/html/html_lists.asp\n",
    "\n",
    "**web page with `ind0` data set**: http://personal.denison.edu/~bressoud/datasystems/ind0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = \"http\"\n",
    "location = \"personal.denison.edu\"\n",
    "resourcepath = \"/~bressoud/datasystems/{}\"\n",
    "\n",
    "url = buildURL(\"ind0.html\")\n",
    "response = requests.get(url)\n",
    "assert response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree3 = etree.parse(io.BytesIO(response.content), parser)\n",
    "root3 = tree3.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovery 1: Find the unordered lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root3.xpath('//ul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are ten, but unlike the table exploration from Example 2, these Element subtrees are not distinct.  They come from different levels based on the nesting, and so most, if not all, of the above are part of the same single dataset.\n",
    "\n",
    "When we check the first of these, we find that it is **not** the one we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(root3.xpath('//ul')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovery 2: Sometimes, particularly for complex pages, we need to narrow in on a subtree, and sometimes an HTML heading level can help us find the subset of the document that we need.  Using Developer Tools, we find that the **ind0** header for the table is an `h2` element, and that the data is (multiple levels down) in a `div` that is sibling to the `h2`.  So we anchor our futher scraping by using XPath and finding the `h2`, going back up a level, and then going down the sibling `div` to the first `ul`.  The `h2` is within a node whose `id` attribute is `\"main-content\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\"//*[@id=\"main-content\"]/h2/../div\"\"\"\n",
    "result = root3.xpath(path)\n",
    "assert len(result) == 1\n",
    "div_ancestor = result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we added `\"//ul\"` or `\"//ul[1]\"`, we end up finding *multiple* results because of the nesting.  The first form will find the top and all subordinate `ul` nodes, the second will find all **first** `ul` nodes, but nested `ul`'s also have a first one.\n",
    "\n",
    "From the ancester div node, we use the subset of XPath capability of the `find()` method to find the *first* descendent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_root = div_ancestor.find(\".//ul\")\n",
    "print_tree(ul_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_indicator = lambda s: (s[:s.index(':')], float(s.split()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedural\n",
    "\n",
    "At least, **after** we got the root of the unordered list subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoD = []\n",
    "for country_list in ul_root:\n",
    "    assert country_list.tag == 'li'\n",
    "    code = country_list.text\n",
    "    for time_list in country_list.find('ul'):\n",
    "        assert time_list.tag == 'li'\n",
    "        if time_list[0].tag == 'span':\n",
    "            year = int(time_list[0].text)\n",
    "        else:\n",
    "            year = int(time_list.text)\n",
    "        rowD = {'code': code, 'year': year}\n",
    "        for indicator in time_list.find('ul'):\n",
    "            ind, value = parse_indicator(indicator.text)\n",
    "            rowD[ind] = value\n",
    "        LoD.append(rowD)\n",
    "LoD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(LoD)\n",
    "df.set_index(['code', 'year'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath Alternative\n",
    "\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Post Example\n",
    "\n",
    "```\n",
    "<form action='index_cms.php' method='post' style='margin-left:10px;'>\n",
    "  <label for='year'>\n",
    "    <select name='year' id='year'>\n",
    "        <option value='2020'>Select Year</option>\n",
    "        <option value='2020'>2020</option>\n",
    "        <option value='2019'>2019</option>\n",
    "        <option value='2018'>2018</option>\n",
    "        <option value='2017'>2017</option>\n",
    "        ...\n",
    "        <option value='1999'>1999</option>\n",
    "    </select>\n",
    "  </label>\n",
    "  <input name='newYear' type='submit' value='Get different year' />\n",
    "</form>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://ww2.energy.ca.gov/almanac/transportation_data/gasoline/margins/index_cms.php\n",
    "\"\"\"\n",
    "\n",
    "protocol = \"https\"\n",
    "location = \"ww2.energy.ca.gov\"\n",
    "resourcepath = \"/almanac/transportation_data/gasoline/margins/index_cms.php\"\n",
    "\n",
    "url = buildURL(resourcepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "assert response.status_code == 200\n",
    "\n",
    "tree4 = etree.parse(io.BytesIO(response.content), parser)\n",
    "root4 = tree4.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form = root4.find(\".//form[@action='index_cms.php']\")\n",
    "print_tree(form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "\n",
    "1. A GET to this resource path results in an HTML page with multiple (weekly) tables, each of which has data of interest.\n",
    "2. The page has a form element, whose `method` attribute is `\"post\"`.  That means that, when the embedded form is \"filled out\" and the user submits the form, an HTTP POST is the result:\n",
    "    - The `action` attribute of the form determines the resource path, relative to the current location, for the URI/resource path needed in the HTTP POST\n",
    "    - The \"form\", in this case, just consists of a dropdown list, whose entries are given by the sequence of `option` nodes, and whose values are the possible years.  The key for this field is called `year`, as given in the `select` node.  The value will be one of the year values.\n",
    "    - The `input` node determines the submission of the form.  In this case, when the user clicks the `\"Get different year\"`, the form will be submitted and, in addition to the key=value items from the form items, the `name` of the `input` attribute, `newYear` will be mapped to the `value` of \"Get different year\".\n",
    "    \n",
    "A second way of gathering this necessary information would be to use a browser's Developer Tools, observe the Network behavior when a user selects a year and submits by hitting the `Get different year` button.  This action will result in the HTTP POST request, and examination of the request will show the POST, the resource path (`index_cms.php`), and the body will show the URL-encoded key-value pairs with entries for keys `year` and `newYear` mapping to the selected year and \"Get different year\", respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emulating an Interactive Form-Based POST\n",
    "\n",
    "We use an HTTP POST to convey information from the client to the server.  The information conveyed is in the $\\textit{body}$ of the request.  So, in contrast to most earlier examples, we need to change two things in using the `requests` module to make this request:\n",
    "\n",
    "1. We must get a POST request instead of a GET request.\n",
    "2. The request must include a body that consists of key-value pairs.\n",
    "\n",
    "For (1), the `requests` module has a `post` top level function.  For (2), we construct a *dictionary* with the desired mappings.  We pass that to the `post()` using named parameter `data`.  The requests module is very flexible in how it interprets an argument provided through `data`.  If it is a string, it simply puts the encoded bytes of the string in the body.  If it is a dictionary, it interprets it and generates a URL-encoded version, as we will see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1998\n",
    "\n",
    "payload = {'year': year, 'newYear': 'Get different year'}\n",
    "response = requests.post(url, data=payload)\n",
    "assert response.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = response.request\n",
    "request.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we use the response to get the request object.  We then examine the body of the request and see a character sequence with key=value mappings, separated by `&`.  Forms in the body of a POST follow the same URL-encoding that we use for query parameters.  Spaces can get mapped to `+` character (or `%20`).  We did not have to perform this formatting for ourselves, the `requests` module can take a mapping dictionary and perform this task for us.\n",
    "\n",
    "W3Schools on URL Encoding: https://www.w3schools.com/tags/ref_urlencode.ASP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.path_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how, also, the requests module informed the server about the format of the body of the post through setting of the `'Content-Type'` header line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Data in the HTML Tree\n",
    "\n",
    "In the result, there is a **table per week**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree4 = etree.parse(io.BytesIO(response.content), parser)\n",
    "root4 = tree4.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another discovery process finds that each of the weekly tables is an immediate chile of a `div` whose `class` attribute is `'contnr``.  This knowledge allows us to directly get the set of weekly tables with a specific xpath and no chance for ambiguity or other tables in the tree to get collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the weekly tables\n",
    "\n",
    "table_list = root4.xpath(\"//div[@class='contnr']/table\")\n",
    "print(len(table_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(table_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that each table represents a single week, and that the rows in the table represent variables, then each table will give us a single row for a table representing the data of the page.  With an eye toward collecting a List of Dictionaries for construction of the table, we will develop processing of one table to result in one (row) dictionary.\n",
    "\n",
    "We can see from the print of the tree, that the first piece of data needed, the date, is in a `caption` child of the `table`.  Let us postulate data columns:\n",
    "\n",
    "`['distrib_cost', 'crude_cost', 'refine_cost', 'storage', 'state_local_tax', 'state_excise_tax', 'fed_excise_tax', 'retail_price']`\n",
    "\n",
    "Assume we just want the `Branded` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['distrib_cost', 'crude_cost', 'refine_cost', 'storage', \n",
    "             'state_local_tax', 'state_excise_tax', 'fed_excise_tax', 'retail_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table_list[0]\n",
    "date = table[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each individual row has one `th` and two `td` nodes, and for the `Branded` data, we want the first of those `td` nodes.  First row contains the Branded/Unbranded header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastrings = table.xpath(\"./tr[position()>1]/td[1]/text()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = [float(s[1:]) for s in datastrings]\n",
    "datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = {key:value for key, value in zip(data_cols, datalist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['date'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a function to process one table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTable(table):\n",
    "    data_cols = ['distrib_cost', 'crude_cost', 'refine_cost', 'storage', \n",
    "                 'state_local_tax', 'state_excise_tax', 'fed_excise_tax', 'retail_price']\n",
    "    date = table[0][0].text\n",
    "    datastrings = table.xpath(\"./tr[position()>1]/td[1]/text()\")\n",
    "    datalist = [float(s[1:]) for s in datastrings]\n",
    "    D = {key:value for key, value in zip(data_cols, datalist)}\n",
    "    D['date'] = date\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a function, we can then easily use a list comprehension to generate our list of dictionaries over the set of tables acquired through our original XPath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoD = [processTable(table) for table in table_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally build our Data Frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(LoD)\n",
    "df.set_index('date', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
